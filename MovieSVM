# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wVsaPG2MxRDTrRgWxXzh_hyM4cm6dCvC
"""

import tensorflow as tf
data = tf.keras.datasets.imdb.load_data(num_words = 10000)
(X_train, Y_train), (X_test, Y_test) = data

# List and understand the data
# Access the word index mapping
word_index = tf.keras.datasets.imdb.get_word_index()

# reverse dictionary mapping integers to words
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

# word indices -> review
def get_review_from_word_index(text):
    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])

# Display reviews from the training data set
for i in range(2):
    review_text = get_review_from_word_index(X_train[i])
    label = Y_train[i]
    print("Review:", review_text)
    print("Label:", label)
    print()

print(X_train[0])
print(Y_train[0])

X_train = [get_review_from_word_index(x) for x in X_train]
X_test = [get_review_from_word_index(x) for x in X_test]

from tensorflow.keras.preprocessing.sequence import pad_sequences

(X_train, Y_train), (X_test, Y_test) = data
# Pad the sequences to have the same length
max_sequence_length = 100  # Maximum length of a review
X_train = pad_sequences(X_train, maxlen=max_sequence_length)
X_test = pad_sequences(X_test, maxlen=max_sequence_length)

from sklearn import svm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Create and train the SVM model
svm_model = svm.SVC(kernel='poly', degree=2, C=0.01)
svm_model.fit(X_train, Y_train)

# Make predictions on the test set
svm_predictions = svm_model.predict(X_test)

# Evaluate the SVM model
accuracy = accuracy_score(Y_test, svm_predictions)
precision = precision_score(Y_test, svm_predictions)
recall = recall_score(Y_test, svm_predictions)
f1 = f1_score(Y_test, svm_predictions)

# Print the evaluation metrics
print("SVM Model Evaluation:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

import numpy as np
from sklearn import svm
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras import models, layers

# Step 1: Load and Prepare the IMDb dataset
num_words = 10000  # Consider only the top 10,000 most frequent words
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)



# Step 5: Training TensorFlow Model
# Reset the data to original text form
word_index = imdb.get_word_index()

# Create a reverse dictionary mapping integers to words
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

# Define a function to convert integers back to text
def decode_review(text):
    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])

# Convert the sequences back to text
X_train_text = [decode_review(x) for x in X_train]
X_test_text = [decode_review(x) for x in X_test]

# Tokenize and pad the text sequences
tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)
tokenizer.fit_on_texts(X_train_text)
X_train_sequences = tokenizer.texts_to_sequences(X_train_text)
X_test_sequences = tokenizer.texts_to_sequences(X_test_text)

max_sequence_length = 100
X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_sequences, maxlen=max_sequence_length)
X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_sequences, maxlen=max_sequence_length)

# Step 6: Training and Evaluation with TensorFlow
model = models.Sequential()
model.add(layers.Embedding(num_words, 64, input_length=max_sequence_length))
model.add(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train_padded, y_train, validation_data=(X_test_padded, y_test), epochs=5, batch_size=64)

tensorflow_predictions = model.predict(X_test_padded)
tensorflow_predictions = np.where(tensorflow_predictions > 0.5, 1, 0)
accuracy = accuracy_score(y_test, tensorflow_predictions)

print("Accuracy:", accuracy)

